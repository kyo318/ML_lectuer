{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "In PyTorch, `Dataset` and `DataLoader` in `torch.utils.data` are used for data preparation.\n",
    "\n",
    "- `Dataset` contains (MNIST, FashionMNIST, CIFAR10, ...)\n",
    "  - Vision Dataset: https://pytorch.org/vision/stable/datasets.html\n",
    "  - Text Dataset: https://pytorch.org/text/stable/datasets.html\n",
    "  - Audio Dataset: https://pytorch.org/audio/stable/datasets.html\n",
    "  - We can determine how to load data through `Dataset`, `batch_size`, `train`, `transform` parameters in `DataLoader`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import time\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`torchvision` provide vision-related dataset\n",
    "\n",
    "- `transforms`: method for preprocessing (https://pytorch.org/docs/stable/torchvision/transforms.html)\n",
    "- Usually, make new class for transform and use it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataLoader`의 인자로 들어갈 `transform`을 미리 정의할 수 있고, `Compose`를 통해 리스트 안에 순서대로 전처리 진행\n",
    "\n",
    "`ToTensor`()를 하는 이유는 `torchvision`이 PIL Image 형태로만 입력을 받기 때문에 데이터 처리를 위해서 Tensor형으로 변환 필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                      transforms.Normalize(mean=(0.5,), std = (1.0, ))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./content/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:00<00:00, 12336479.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./content/MNIST/raw/train-images-idx3-ubyte.gz to ./content/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./content/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 111851979.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./content/MNIST/raw/train-labels-idx1-ubyte.gz to ./content/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./content/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:00<00:00, 17383119.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./content/MNIST/raw/t10k-images-idx3-ubyte.gz to ./content/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./content/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<00:00, 21846936.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./content/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./content/MNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "trainset = datasets.MNIST(root='./content/',\n",
    "                          train=True, download=True,\n",
    "                          transform = mnist_transform)\n",
    "testset = datasets.MNIST(root='./content/',\n",
    "                          train=False, download=True,\n",
    "                          transform = mnist_transform)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataLoader`는 데이터 전체를 보관했다가 실제 모델 학습을 할 때 `batch_size` 크기만큼 데이터를 가져옴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#batch size\n",
    "bs = 8\n",
    "train_loader = DataLoader(trainset, batch_size=bs, shuffle=True, num_workers=2)\n",
    "test_loader = DataLoader(testset, batch_size=bs, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8, 1, 28, 28]), torch.Size([8]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataiter = iter(train_loader)\n",
    "images, labels = next(dataiter)\n",
    "images.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([28, 28])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_image = torch.squeeze(images[0])\n",
    "torch_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 8 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "figure = plt.figure(figsize=(12, 6))\n",
    "cols, rows = 4, 2\n",
    "for i in range(1, cols * rows + 1):\n",
    "  sample_idx = torch.randint(len(trainset), size=(1, )).item()\n",
    "  img, label = trainset[sample_idx]\n",
    "  figure.add_subplot(rows, cols, i)\n",
    "  plt.title(label)\n",
    "  plt.axis(\"off\")\n",
    "  plt.imshow(img.squeeze(), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST Classification Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPU 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(trainset, batch_size = 128, shuffle=True, num_workers=2)\n",
    "test_loader = DataLoader(testset, batch_size = 128, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([128, 1, 28, 28]), torch.Size([128]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images, labels = next(iter(train_loader))\n",
    "images.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_Model, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1, 1)\n",
    "        #self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 16, 2, 1, 1)\n",
    "        self.fc1 = nn.Linear(784, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 1, 28, 28)\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = nn.Flatten()(x)\n",
    "        x = self.fc1(x)\n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN_Model(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv2): Conv2d(32, 16, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
      "  (fc1): Linear(in_features=784, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = CNN_Model()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [01:03<00:00,  7.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1/5 Loss = 0.015405458398163319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65.18004608154297 sec - acc : 98.33 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [01:10<00:00,  6.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2/5 Loss = 0.0022374435793608427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72.2155613899231 sec - acc : 98.4 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [01:05<00:00,  7.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3/5 Loss = 0.13770116865634918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67.34073805809021 sec - acc : 98.4 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [01:03<00:00,  7.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4/5 Loss = 0.06318273395299911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64.79645776748657 sec - acc : 98.34 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [01:01<00:00,  7.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5/5 Loss = 0.014957382343709469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63.54617381095886 sec - acc : 98.12 %\n"
     ]
    }
   ],
   "source": [
    "\n",
    "epochs = 5\n",
    "losses = []\n",
    "for epoch in range(1, epochs + 1):\n",
    "    start = time.time()\n",
    "    total_loss = 0\n",
    " \n",
    "    #for xb, yb in train_loader:\n",
    "    for xb, yb in tqdm(train_loader):\n",
    "        pred = model(xb)\n",
    "        loss = criterion(pred, yb.long())\n",
    " \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    " \n",
    "        total_loss += loss.item()\n",
    "    print(f\"epoch {epoch}/{epochs} Loss = {loss.item()}\")\n",
    "    \n",
    "    correct = 0\n",
    "    total   = 0\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            images, labels = data\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        acc = 100 * correct / total\n",
    "        print(f\"{time.time() - start} sec - acc : {acc} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchsummary\n",
      "  Downloading torchsummary-1.5.1-py3-none-any.whl (2.8 kB)\n",
      "Installing collected packages: torchsummary\n",
      "Successfully installed torchsummary-1.5.1\n"
     ]
    }
   ],
   "source": [
    "!pip install torchsummary\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 32, 28, 28]             320\n",
      "            Conv2d-2           [-1, 16, 15, 15]           2,064\n",
      "            Linear-3                   [-1, 10]           7,850\n",
      "================================================================\n",
      "Total params: 10,234\n",
      "Trainable params: 10,234\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.22\n",
      "Params size (MB): 0.04\n",
      "Estimated Total Size (MB): 0.26\n",
      "----------------------------------------------------------------\n",
      "None\n",
      "28\n",
      "320\n",
      "2064\n",
      "7840\n"
     ]
    }
   ],
   "source": [
    "print(summary(model, (28, 28)))\n",
    "print(28 - 3 + 2 * 1 + 1)\n",
    "print(3 * 3 * 32 + 32)\n",
    "print(2*2*32*16 + 16)\n",
    "print(7*7*16*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_RL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
